*vim-ai.txt*  Complete text using OpenAI API.

Author:  Martin Bielik <https://madox2.poriadne.sk/>
License: see https://github.com/guilt/vim-ai/blob/main/LICENSE

INTRODUCTION                                    *vim-ai*

This plugin can be used to generate code, edit text, brainstorm ideas,
translate, etc. It includes context-aware roles that automatically understand
your project structure and provide enhanced AI assistance.

COMMANDS                                        *vim-ai-commands*

To set-up key bindings and examples see:
https://github.com/guilt/vim-ai

                                                *:AI*

:AI {prompt}                        complete the prompt
<selection> :AI                     complete the selection
<selection> :AI {instruction}       complete the selection using the instruction

Options: >
  let s:initial_complete_prompt =<< trim END
  >>> system

  You are a general assistant.
  Answer shortly, consisely and only what you are asked.
  Do not provide any explanantion or comments if not requested.
  If you answer in a code, do not wrap it in markdown code block.
  END

  let g:vim_ai_complete = {
  \  "provider": "openai",
  \  "prompt": "",
  \  "options": {
  \    "model": "gpt-4o",
  \    "endpoint_url": "https://api.openai.com/v1/chat/completions",
  \    "max_tokens": 0,
  \    "max_completion_tokens": 0,
  \    "temperature": 0.1,
  \    "request_timeout": 20,
  \    "stream": 1,
  \    "auth_type": "bearer",
  \    "token_file_path": "",
  \    "token_load_fn": "",
  \    "selection_boundary": "#####",
  \    "initial_prompt": s:initial_complete_prompt,
  \    "frequency_penalty": "",
  \    "logit_bias": "",
  \    "logprobs": "",
  \    "presence_penalty": "",
  \    "reasoning_effort": "",
  \    "seed": "",
  \    "stop": "",
  \    "top_logprobs": "",
  \    "top_p": "",
  \  },
  \  "ui": {
  \    "paste_mode": 1,
  \  },
  \}

Check OpenAI docs for more information:
https://platform.openai.com/docs/api-reference/completions

                                                *:AIEdit*

<selection>? :AIEdit                edit the current line or the selection
<selection>? :AIEdit {instruction}  edit the current line or the selection using
                                    the instruction

Options: >
  let s:initial_complete_prompt =<< trim END
  >>> system

  You are a general assistant.
  Answer shortly, consisely and only what you are asked.
  Do not provide any explanantion or comments if not requested.
  If you answer in a code, do not wrap it in markdown code block.
  END

  let g:vim_ai_edit = {
  \  "provider": "openai",
  \  "prompt": "",
  \  "options": {
  \    "model": "gpt-4o",
  \    "endpoint_url": "https://api.openai.com/v1/chat/completions",
  \    "max_tokens": 0,
  \    "max_completion_tokens": 0,
  \    "temperature": 0.1,
  \    "request_timeout": 20,
  \    "stream": 1,
  \    "auth_type": "bearer",
  \    "token_file_path": "",
  \    "token_load_fn": "",
  \    "selection_boundary": "#####",
  \    "initial_prompt": s:initial_complete_prompt,
  \    "frequency_penalty": "",
  \    "logit_bias": "",
  \    "logprobs": "",
  \    "presence_penalty": "",
  \    "reasoning_effort": "",
  \    "seed": "",
  \    "stop": "",
  \    "top_logprobs": "",
  \    "top_p": "",
  \  },
  \  "ui": {
  \    "paste_mode": 1,
  \  },
  \}

Check OpenAI docs for more information:
https://platform.openai.com/docs/api-reference/completions

                                                *:AIChat*

:AIChat                             continue or start a new conversation.
<selection>? :AIChat {instruction}? start a new conversation given the selection,
                                    the instruction or both

Tip: Use context-aware roles like `/codebase`, `/refactor`, `/debug`, `/review` 
for enhanced project understanding.

Options: >
  let s:initial_chat_prompt =<< trim END
  >>> system

  You are a general assistant.
  If you attach a code block add syntax type after ``` to enable syntax highlighting.
  END

  let g:vim_ai_chat = {
  \  "provider": "openai",
  \  "prompt": "",
  \  "options": {
  \    "model": "gpt-4o",
  \    "max_tokens": 0,
  \    "max_completion_tokens": 0,
  \    "endpoint_url": "https://api.openai.com/v1/chat/completions",
  \    "temperature": 1,
  \    "request_timeout": 20,
  \    "stream": 1,
  \    "auth_type": "bearer",
  \    "token_file_path": "",
  \    "token_load_fn": "",
  \    "selection_boundary": "",
  \    "initial_prompt": s:initial_chat_prompt,
  \    "frequency_penalty": "",
  \    "logit_bias": "",
  \    "logprobs": "",
  \    "presence_penalty": "",
  \    "reasoning_effort": "",
  \    "seed": "",
  \    "stop": "",
  \    "top_logprobs": "",
  \    "top_p": "",
  \  },
  \  "ui": {
  \    "populate_options": 0,
  \    "populate_all_options": 0,
  \    "open_chat_command": "preset_below",
  \    "scratch_buffer_keep_open": 0,
  \    "paste_mode": 1,
  \  },
  \}

Check OpenAI docs for more information:
https://platform.openai.com/docs/api-reference/chat

                                                *:AIStopChat*
AIStopChat                          Cancel the currently running AI chat
                                    generation for the active chat buffer.
                                    If no task is running or if it has already
                                    completed, this command has no effect.


INCLUDE FILES                                  *vim-ai-include*

To include files in the chat a special `include` role is used: >

  >>> user

  Generate documentation for the following files

  >>> include

  /home/user/myproject/requirements.txt
  /home/user/myproject/**/*.py

Each file's contents will be added to an additional `user` role message with
the files separated by `==> {path} <==`, where path is the path to the file.
Globbing is expanded out via `glob.gob` and relative paths to the current
working directory (as determined by `getcwd()`) will be resolved to absolute
paths.

                                                *:AIImage*

<selection>? :AIImage {instruction}? generate image given the selection or
                                     the instruction

Options: >
  let g:vim_ai_image = {
  \  "provider": "openai",
  \  "prompt": "",
  \  "options": {
  \    "model": "dall-e-3",
  \    "endpoint_url": "https://api.openai.com/v1/images/generations",
  \    "quality": "standard",
  \    "size": "1024x1024",
  \    "style": "vivid",
  \    "request_timeout": 40,
  \    "auth_type": "bearer",
  \    "token_file_path": "",
  \    "token_load_fn": "",
  \  },
  \  "ui": {
  \    "download_dir": "",
  \  },
  \}

Check OpenAI docs for more information:
https://platform.openai.com/docs/api-reference/images/create

                                                *:AIRedo*

:AIRedo                             repeat last AI command in order to re-try
                                    or get an alternative completion.

                                                *:AIUtilRolesOpen*

:AIUtilRolesOpen                    open role configuration file

                                                *:AIUtilDebugOn*

:AIUtilDebugOn                      turn on debug logging

                                                *:AIUtilDebugOff*

:AIUtilDebugOff                     turn off debug logging


CONFIGURATION                                   *vim-ai-config*

To customize the default configuration, initialize the config variable with
a selection of options: >

  let g:vim_ai_chat = {
  \  "options": {
  \    "model": "gpt-4",
  \    "temperature": 0.2,
  \  },
  \}

Alternatively you can use special `default` role: >

  [default.chat]
  options.model=gpt-4
  options.temperature=0.2

You can also customize the options in the chat header: >

  [chat]
  options.model=gpt-4
  options.temperature=0.2

  >>> user

  generate a paragraph of lorem ipsum
  ...

PROVIDERS                                       *vim-ai-providers*

Built-in Providers:

- OpenAI - Default provider for OpenAI's GPT models, works with vLLM, 
  llama.cpp and OpenAI compatible providers.
- Amazon Q - Amazon Q Developer for code assistance and general AI tasks
- Amazon Bedrock - Access to Claude, Stability AI, and other models via 
  AWS Bedrock (supports chat, completion, and image generation)

Global Provider Configuration:

Instead of configuring each command individually, use the global provider 
setting: >

  # Option 1: Environment variable
  export VIM_AI_PROVIDER=amazonq

  # Option 2: .vimrc setting
  let g:vim_ai_provider = "amazonq"

This automatically configures all AI commands to use the specified provider.

Available providers: openai (default), amazonq, bedrock, or any custom provider

Amazon Q Provider Example:

To use Amazon Q, authenticate using the Q CLI: >

  # Login to Amazon Q
  q login

Then configure roles to use Amazon Q: >

  [amazonq]
  provider = amazonq

  [amazonq-code]
  provider = amazonq
  prompt = You are an expert software developer. Help with code-related tasks.

Amazon Bedrock Provider Example:

To use Amazon Bedrock, ensure AWS CLI is configured with Bedrock access: >

  # Configure AWS CLI (if not already done)
  aws configure

Then configure roles to use Bedrock: >

  [bedrock]
  provider = bedrock
  options.model = amazon.nova-micro-v1:0
  options.region = us-east-1
  options.profile = my-aws-profile

Custom API Configuration:

It is possible to configure the plugin to use different OpenAI-compatible 
endpoints: >

  let g:vim_ai_chat = {
  \  "options": {
  \    "endpoint_url": "http://localhost:8000/v1/chat/completions",
  \    "auth_type": "none",
  \  },
  \}

ROLES                                           *vim-ai-roles*

Roles are defined in the `.ini` file: >

    let g:vim_ai_roles_config_file = '/path/to/my/roles.ini'

Example of a role: >

    [grammar]
    prompt = fix spelling and grammar
    options.temperature = 0.4

Now you can select text and run it with command `:AIEdit /grammar`.
See roles-example.ini for more examples.

CONTEXT-AWARE ROLES                             *vim-ai-context-roles*

vim-ai includes built-in roles that automatically understand your project context:

- `/codebase` - Code assistant with full project awareness
- `/refactor` - Refactoring expert that considers code structure  
- `/debug` - Debugging specialist with context analysis
- `/review` - Code reviewer with project understanding
- `/architect` - Software architect for system design
- `/test` - Testing expert for comprehensive test generation
- `/docs` - Documentation specialist
- `/git` - Git workflow expert with repository awareness
- `/project` - Project analyst for codebase insights

These roles automatically include relevant project information like file 
structure, current file context, and git status when appropriate.

Example: >
    :AIChat /codebase
    " Automatically includes project structure and current file context

    :AIEdit /refactor optimize this function
    " Includes related files and project patterns for better refactoring

The roles in g:vim_ai_roles_config_file are converted to a Vim dictionary whose
labels are the names of the roles. Optionally, roles can be added by setting
g:vim_ai_roles_config_function to the name of a Vimscript function returning a
dictionary of the same format as g:vim_ai_roles_config_file.

MARKDOWN HIGHLIGHTING                            *g:vim_ai_chat_markdown*

Set g:vim_ai_chat_markdown = 1 to enable full markdown highlighting in aichat files.
Highlighting may be corrupted when using the preservim/vim-markdown plugin.

KEY BINDINGS

Examples how configure key bindings and customize commands: >

  " complete text on the current line or in visual selection
  nnoremap <leader>a :AI<CR>
  xnoremap <leader>a :AI<CR>

  " edit text with custom context
  xnoremap <leader>s :AIEdit fix grammar and spelling<CR>
  nnoremap <leader>s :AIEdit fix grammar and spelling<CR>

  " trigger chat
  xnoremap <leader>c :AIChat<CR>
  nnoremap <leader>c :AIChat<CR>

  " redo last AI command
  nnoremap <leader>r :AIRedo<CR>

CUSTOM COMMANDS

To create custom commands, call `AIRun`, `AIEditRun` and `AIChatRun` functions: >

  " custom command suggesting git commit message, takes no arguments
  function! AIPromptCommitMessageFn()
    let l:range = 0
    let l:diff = system('git diff --staged')
    let l:prompt = "generate a short commit message from the diff below:\n" . l:diff
    let l:config = {
    \  "options": {
    \    "model": "gpt-4o",
    \    "initial_prompt": ">>> system\nyou are a code assistant",
    \    "temperature": 1,
    \  },
    \}
    call vim_ai#AIRun(l:range, l:config, l:prompt)
  endfunction
  command! AIPromptCommitMessage call AIPromptCommitMessageFn(range)

  " Enhanced custom commands using context-aware roles
  
  " Code review with automatic project context
  function! AIPromptCodeReviewFn() range
    '<,'>call vim_ai#AIChatRun(a:range, {}, '/review')
  endfunction
  command! -range=0 AIPromptCodeReview <line1>,<line2>call AIPromptCodeReviewFn(<count>)
  
  " Simplified commands using context-aware roles
  command! -range CodeReview <line1>,<line2>AIChat /review
  command! -range Refactor <line1>,<line2>AIEdit /refactor
  command! GitCommit AI /git generate a commit message for staged changes

ABOUT                                           *vim-ai-about*

Contributions are welcome on GitHub:

https://github.com/guilt/vim-ai
